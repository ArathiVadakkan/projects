{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyuXSLRLVTEj",
        "outputId": "17e7c35c-87d5-40a3-826a-bfcdf9f08dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT2LMHeadModel and GPT2Tokenizer  are classes from the Hugging Face Transformers library, which is a popular library for working with various pre-trained language models, including GPT-2. These classes are used to load and utilize the GPT-2 model for text generation tasks.\n",
        "\n",
        "***GPT2LMHeadModel***: This class represents the GPT-2 model for language modeling tasks. It's designed to predict the next word in a sequence given the context of the previous words. You can use it for tasks like text completion, text generation, and more.\n",
        "\n",
        "***GPT2Tokenizer***: This class is used to tokenize text into smaller units (subwords or words) that can be fed into the GPT-2 model. It's responsible for converting text into numerical tokens that the model can process.\n",
        "\n",
        "\n",
        "\n",
        "In the context of using models like GPT-2, attention masks and pad token IDs are crucial components that help the model process sequences correctly and generate meaningful output. Let's dive deeper into these concepts:\n",
        "\n",
        "***Attention Mask:***\n",
        "The attention mask is a binary mask that tells the model which tokens in the input sequence should be attended to (given attention to) and which should be ignored. In most cases, it's used to mask padding tokens to prevent the model from paying attention to them. It's a tensor of the same shape as the input sequence and consists of 1s (attend) and 0s (ignore).\n",
        "\n",
        "**Pad Token ID:**\n",
        "The pad token ID represents the token used to pad sequences to make them equal in length. In the context of language modeling, it's common to pad sequences to the length of the longest sequence in the dataset. The pad token is a special token that has a unique ID in the vocabulary."
      ],
      "metadata": {
        "id": "YeKE5igxY1Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = 'gpt2-medium'  # You can choose different sizes like 'gpt2', 'gpt2-medium', 'gpt2-large'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "J0pQskTVVtfy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generate(prompt):\n",
        "  input_ids = tokenizer.encode(prompt, add_special_tokens=True, return_tensors='pt')\n",
        "\n",
        "  # Attention Mask\n",
        "  attention_mask = torch.ones(input_ids.shape, dtype=torch.long)  # All tokens should be attended to\n",
        "  attention_mask = attention_mask.to(input_ids.device)\n",
        "\n",
        "  # Pad Token ID\n",
        "  pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "  # Generate text\n",
        "  output = model.generate(input_ids, attention_mask=attention_mask, max_length=100,\n",
        "                        num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=pad_token_id)\n",
        "\n",
        "  generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "  print(\"Generated Text:\")\n",
        "  print(generated_text)"
      ],
      "metadata": {
        "id": "4KeoKG0vWWrl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test Case"
      ],
      "metadata": {
        "id": "lsOSWNIraDSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"Once upon a time\"\n",
        "Generate(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TH-xHG7V3hu",
        "outputId": "1be9379e-a552-47f8-f080-8e15afda0af7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "Once upon a time, there was a man who lived in a village called Krakow. He was an old man, and he had a daughter. She was beautiful, but she was very shy. One day, she came to him and said, \"I want to go to the opera.\" He said to her, \"'You are not going to be able to do it, because you are too young.\" She said: \"Well, I am going.\" So he took her to a theater\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"There lived a king\"\n",
        "Generate(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VIC96j3WnfT",
        "outputId": "5e554e33-9527-418b-df32-2b0129edbbd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "There lived a king, and he was called King David. And he had a son, called Solomon.\n",
            "\n",
            "And Solomon went up to the house of the king of Israel, to meet him. So Solomon said to him, \"I am the son of David, the father of your father, who is called David.\"\n",
            ",\n",
            "...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"Once upon a time in India\"\n",
        "Generate(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wzkJTD_aI5X",
        "outputId": "ff2e4f3c-e901-430f-bbb2-86b7309068b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "Once upon a time in India, the country was ruled by a king who was known as the \"King of Kings\". The king was a man named Ramakrishna. Ramachandra was the son of Ramana Maharshi, who had been the king of the kingdom of Kurukshetra.\n",
            "\n",
            "Ramakriya was born in the year 732 AD. He was one of a number of kings who ruled the land of India. His father was Ramanuja,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOuJAWZcbNol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}